{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "babecfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98ac88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"music_features.csv\")\n",
    "\n",
    "# Convert stringified lists to actual Python lists\n",
    "for col in [\"Tempo\", \"Chroma\", \"MFCC\", \"Chords\"]:\n",
    "    df[col] = df[col].apply(ast.literal_eval)\n",
    "\n",
    "# Combine features\n",
    "df[\"Features\"] = df.apply(lambda row: row[\"Tempo\"] + row[\"Chroma\"] + row[\"MFCC\"], axis=1)\n",
    "X = np.stack(df[\"Features\"].values)\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Pad to 36 and reshape to 6x6x1\n",
    "X_padded = np.zeros((X_scaled.shape[0], 36))\n",
    "X_padded[:, :X_scaled.shape[1]] = X_scaled\n",
    "X_cnn = X_padded.reshape(-1, 6, 6, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38f7e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chord_histogram(chords, num_classes=12):\n",
    "    hist = np.zeros(num_classes)\n",
    "    for c in chords:\n",
    "        if 0 <= c < num_classes:\n",
    "            hist[c] += 1\n",
    "    return hist / len(chords)\n",
    "\n",
    "y = np.stack(df[\"Chords\"].apply(lambda x: chord_histogram(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1def337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 4, 4, 32)          320       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                780       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,932\n",
      "Trainable params: 33,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_chord_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(6, 6, 1)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(12, activation='softmax')  # Predict chord class distribution\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_chord_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50122ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/121\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.6936 - accuracy: 0.4901 - val_loss: 3.3542 - val_accuracy: 0.2022\n",
      "Epoch 2/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6804 - accuracy: 0.5859 - val_loss: 3.3547 - val_accuracy: 0.2360\n",
      "Epoch 3/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6747 - accuracy: 0.4901 - val_loss: 3.3739 - val_accuracy: 0.2360\n",
      "Epoch 4/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6725 - accuracy: 0.4958 - val_loss: 3.3631 - val_accuracy: 0.2360\n",
      "Epoch 5/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6643 - accuracy: 0.6479 - val_loss: 3.3784 - val_accuracy: 0.1910\n",
      "Epoch 6/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6613 - accuracy: 0.5831 - val_loss: 3.3736 - val_accuracy: 0.2472\n",
      "Epoch 7/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6587 - accuracy: 0.5887 - val_loss: 3.3899 - val_accuracy: 0.2360\n",
      "Epoch 8/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6565 - accuracy: 0.6197 - val_loss: 3.4001 - val_accuracy: 0.2360\n",
      "Epoch 9/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6619 - accuracy: 0.6000 - val_loss: 3.3973 - val_accuracy: 0.2135\n",
      "Epoch 10/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6626 - accuracy: 0.5634 - val_loss: 3.4173 - val_accuracy: 0.2584\n",
      "Epoch 11/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6616 - accuracy: 0.5606 - val_loss: 3.4228 - val_accuracy: 0.2360\n",
      "Epoch 12/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6601 - accuracy: 0.5718 - val_loss: 3.4012 - val_accuracy: 0.2360\n",
      "Epoch 13/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6600 - accuracy: 0.5831 - val_loss: 3.4288 - val_accuracy: 0.2472\n",
      "Epoch 14/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6570 - accuracy: 0.6000 - val_loss: 3.4143 - val_accuracy: 0.2135\n",
      "Epoch 15/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6552 - accuracy: 0.5577 - val_loss: 3.4150 - val_accuracy: 0.2472\n",
      "Epoch 16/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6549 - accuracy: 0.6507 - val_loss: 3.4311 - val_accuracy: 0.2247\n",
      "Epoch 17/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6552 - accuracy: 0.6113 - val_loss: 3.4387 - val_accuracy: 0.2247\n",
      "Epoch 18/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6548 - accuracy: 0.6254 - val_loss: 3.4366 - val_accuracy: 0.2247\n",
      "Epoch 19/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6563 - accuracy: 0.5859 - val_loss: 3.4549 - val_accuracy: 0.2247\n",
      "Epoch 20/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6566 - accuracy: 0.5577 - val_loss: 3.4419 - val_accuracy: 0.2360\n",
      "Epoch 21/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6562 - accuracy: 0.5718 - val_loss: 3.4666 - val_accuracy: 0.2360\n",
      "Epoch 22/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6582 - accuracy: 0.5662 - val_loss: 3.4225 - val_accuracy: 0.2360\n",
      "Epoch 23/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6598 - accuracy: 0.6000 - val_loss: 3.4471 - val_accuracy: 0.2360\n",
      "Epoch 24/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6625 - accuracy: 0.5352 - val_loss: 3.4802 - val_accuracy: 0.2360\n",
      "Epoch 25/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6630 - accuracy: 0.5634 - val_loss: 3.4403 - val_accuracy: 0.2247\n",
      "Epoch 26/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6624 - accuracy: 0.5014 - val_loss: 3.4487 - val_accuracy: 0.2022\n",
      "Epoch 27/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6674 - accuracy: 0.5718 - val_loss: 3.4407 - val_accuracy: 0.2247\n",
      "Epoch 28/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6691 - accuracy: 0.5239 - val_loss: 3.4791 - val_accuracy: 0.2247\n",
      "Epoch 29/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6680 - accuracy: 0.5521 - val_loss: 3.4256 - val_accuracy: 0.2022\n",
      "Epoch 30/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6695 - accuracy: 0.5493 - val_loss: 3.4332 - val_accuracy: 0.2247\n",
      "Epoch 31/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6736 - accuracy: 0.5211 - val_loss: 3.4593 - val_accuracy: 0.2472\n",
      "Epoch 32/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6707 - accuracy: 0.5775 - val_loss: 3.4775 - val_accuracy: 0.2360\n",
      "Epoch 33/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6716 - accuracy: 0.5183 - val_loss: 3.4504 - val_accuracy: 0.2360\n",
      "Epoch 34/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6731 - accuracy: 0.5183 - val_loss: 3.4410 - val_accuracy: 0.2247\n",
      "Epoch 35/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6727 - accuracy: 0.5493 - val_loss: 3.4011 - val_accuracy: 0.1910\n",
      "Epoch 36/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6659 - accuracy: 0.5437 - val_loss: 3.3657 - val_accuracy: 0.1910\n",
      "Epoch 37/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6669 - accuracy: 0.5268 - val_loss: 3.4203 - val_accuracy: 0.2472\n",
      "Epoch 38/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6746 - accuracy: 0.5662 - val_loss: 3.3766 - val_accuracy: 0.2360\n",
      "Epoch 39/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6736 - accuracy: 0.4789 - val_loss: 3.4219 - val_accuracy: 0.2360\n",
      "Epoch 40/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6732 - accuracy: 0.5352 - val_loss: 3.4055 - val_accuracy: 0.2360\n",
      "Epoch 41/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6669 - accuracy: 0.5662 - val_loss: 3.3984 - val_accuracy: 0.2360\n",
      "Epoch 42/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6646 - accuracy: 0.5746 - val_loss: 3.3817 - val_accuracy: 0.1910\n",
      "Epoch 43/121\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.6609 - accuracy: 0.5352 - val_loss: 3.4175 - val_accuracy: 0.2360\n",
      "Epoch 44/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6596 - accuracy: 0.6056 - val_loss: 3.4164 - val_accuracy: 0.2135\n",
      "Epoch 45/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6571 - accuracy: 0.5803 - val_loss: 3.4214 - val_accuracy: 0.2135\n",
      "Epoch 46/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6603 - accuracy: 0.5831 - val_loss: 3.4149 - val_accuracy: 0.2584\n",
      "Epoch 47/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6604 - accuracy: 0.5352 - val_loss: 3.3930 - val_accuracy: 0.2584\n",
      "Epoch 48/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6613 - accuracy: 0.5831 - val_loss: 3.4207 - val_accuracy: 0.2135\n",
      "Epoch 49/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.5831 - val_loss: 3.4110 - val_accuracy: 0.2247\n",
      "Epoch 50/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6582 - accuracy: 0.5775 - val_loss: 3.4020 - val_accuracy: 0.2360\n",
      "Epoch 51/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6575 - accuracy: 0.5859 - val_loss: 3.4385 - val_accuracy: 0.2135\n",
      "Epoch 52/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6570 - accuracy: 0.5831 - val_loss: 3.4293 - val_accuracy: 0.2360\n",
      "Epoch 53/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6557 - accuracy: 0.6225 - val_loss: 3.4281 - val_accuracy: 0.2360\n",
      "Epoch 54/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6582 - accuracy: 0.5775 - val_loss: 3.4521 - val_accuracy: 0.2360\n",
      "Epoch 55/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6573 - accuracy: 0.6000 - val_loss: 3.4589 - val_accuracy: 0.2472\n",
      "Epoch 56/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6573 - accuracy: 0.6085 - val_loss: 3.4397 - val_accuracy: 0.2360\n",
      "Epoch 57/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6564 - accuracy: 0.5493 - val_loss: 3.4542 - val_accuracy: 0.2360\n",
      "Epoch 58/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6583 - accuracy: 0.6000 - val_loss: 3.4809 - val_accuracy: 0.2472\n",
      "Epoch 59/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6596 - accuracy: 0.5634 - val_loss: 3.4815 - val_accuracy: 0.2247\n",
      "Epoch 60/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6674 - accuracy: 0.5493 - val_loss: 3.4610 - val_accuracy: 0.2360\n",
      "Epoch 61/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6655 - accuracy: 0.5296 - val_loss: 3.5136 - val_accuracy: 0.2360\n",
      "Epoch 62/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6659 - accuracy: 0.5296 - val_loss: 3.4450 - val_accuracy: 0.2472\n",
      "Epoch 63/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6633 - accuracy: 0.5437 - val_loss: 3.4613 - val_accuracy: 0.2472\n",
      "Epoch 64/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6663 - accuracy: 0.5803 - val_loss: 3.4554 - val_accuracy: 0.2247\n",
      "Epoch 65/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6643 - accuracy: 0.5296 - val_loss: 3.4822 - val_accuracy: 0.2360\n",
      "Epoch 66/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6676 - accuracy: 0.5577 - val_loss: 3.4361 - val_accuracy: 0.2247\n",
      "Epoch 67/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6657 - accuracy: 0.5915 - val_loss: 3.4765 - val_accuracy: 0.2022\n",
      "Epoch 68/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6610 - accuracy: 0.5211 - val_loss: 3.4394 - val_accuracy: 0.2247\n",
      "Epoch 69/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6594 - accuracy: 0.5972 - val_loss: 3.4529 - val_accuracy: 0.2360\n",
      "Epoch 70/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6578 - accuracy: 0.5690 - val_loss: 3.4621 - val_accuracy: 0.2135\n",
      "Epoch 71/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6571 - accuracy: 0.5746 - val_loss: 3.4484 - val_accuracy: 0.2360\n",
      "Epoch 72/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6570 - accuracy: 0.5803 - val_loss: 3.4753 - val_accuracy: 0.2360\n",
      "Epoch 73/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6567 - accuracy: 0.5718 - val_loss: 3.4848 - val_accuracy: 0.2247\n",
      "Epoch 74/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6569 - accuracy: 0.6028 - val_loss: 3.4557 - val_accuracy: 0.2247\n",
      "Epoch 75/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6570 - accuracy: 0.5944 - val_loss: 3.4857 - val_accuracy: 0.2472\n",
      "Epoch 76/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6569 - accuracy: 0.5549 - val_loss: 3.4798 - val_accuracy: 0.2472\n",
      "Epoch 77/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6587 - accuracy: 0.5690 - val_loss: 3.4756 - val_accuracy: 0.2360\n",
      "Epoch 78/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6593 - accuracy: 0.5944 - val_loss: 3.4810 - val_accuracy: 0.2247\n",
      "Epoch 79/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6618 - accuracy: 0.5493 - val_loss: 3.4899 - val_accuracy: 0.2697\n",
      "Epoch 80/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6613 - accuracy: 0.5746 - val_loss: 3.4858 - val_accuracy: 0.2247\n",
      "Epoch 81/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6636 - accuracy: 0.5690 - val_loss: 3.4832 - val_accuracy: 0.2247\n",
      "Epoch 82/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6666 - accuracy: 0.5662 - val_loss: 3.4834 - val_accuracy: 0.2472\n",
      "Epoch 83/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6664 - accuracy: 0.5577 - val_loss: 3.4587 - val_accuracy: 0.1798\n",
      "Epoch 84/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6658 - accuracy: 0.5690 - val_loss: 3.4630 - val_accuracy: 0.2022\n",
      "Epoch 85/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6663 - accuracy: 0.5775 - val_loss: 3.4630 - val_accuracy: 0.2247\n",
      "Epoch 86/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6719 - accuracy: 0.5493 - val_loss: 3.4641 - val_accuracy: 0.2247\n",
      "Epoch 87/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6657 - accuracy: 0.5915 - val_loss: 3.4428 - val_accuracy: 0.2022\n",
      "Epoch 88/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6644 - accuracy: 0.5408 - val_loss: 3.4636 - val_accuracy: 0.2472\n",
      "Epoch 89/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6632 - accuracy: 0.5577 - val_loss: 3.4795 - val_accuracy: 0.2472\n",
      "Epoch 90/121\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6616 - accuracy: 0.5296 - val_loss: 3.4772 - val_accuracy: 0.2360\n",
      "Epoch 91/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6605 - accuracy: 0.5972 - val_loss: 3.4603 - val_accuracy: 0.2247\n",
      "Epoch 92/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6611 - accuracy: 0.5718 - val_loss: 3.4668 - val_accuracy: 0.2360\n",
      "Epoch 93/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6615 - accuracy: 0.5634 - val_loss: 3.4347 - val_accuracy: 0.2022\n",
      "Epoch 94/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6624 - accuracy: 0.5775 - val_loss: 3.4383 - val_accuracy: 0.2247\n",
      "Epoch 95/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6617 - accuracy: 0.5634 - val_loss: 3.4689 - val_accuracy: 0.2472\n",
      "Epoch 96/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6595 - accuracy: 0.5239 - val_loss: 3.4768 - val_accuracy: 0.2247\n",
      "Epoch 97/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6589 - accuracy: 0.6197 - val_loss: 3.4764 - val_accuracy: 0.2022\n",
      "Epoch 98/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6582 - accuracy: 0.5549 - val_loss: 3.4487 - val_accuracy: 0.2022\n",
      "Epoch 99/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6592 - accuracy: 0.5887 - val_loss: 3.5055 - val_accuracy: 0.2584\n",
      "Epoch 100/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6630 - accuracy: 0.5634 - val_loss: 3.4536 - val_accuracy: 0.2472\n",
      "Epoch 101/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6632 - accuracy: 0.5606 - val_loss: 3.5283 - val_accuracy: 0.2584\n",
      "Epoch 102/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6648 - accuracy: 0.5662 - val_loss: 3.4490 - val_accuracy: 0.2360\n",
      "Epoch 103/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6636 - accuracy: 0.5887 - val_loss: 3.4909 - val_accuracy: 0.2247\n",
      "Epoch 104/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6629 - accuracy: 0.5521 - val_loss: 3.4824 - val_accuracy: 0.2360\n",
      "Epoch 105/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6641 - accuracy: 0.5803 - val_loss: 3.4917 - val_accuracy: 0.2360\n",
      "Epoch 106/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6637 - accuracy: 0.5606 - val_loss: 3.4622 - val_accuracy: 0.2360\n",
      "Epoch 107/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6654 - accuracy: 0.5662 - val_loss: 3.4643 - val_accuracy: 0.2360\n",
      "Epoch 108/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6650 - accuracy: 0.5746 - val_loss: 3.4543 - val_accuracy: 0.2135\n",
      "Epoch 109/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6636 - accuracy: 0.5437 - val_loss: 3.4925 - val_accuracy: 0.2584\n",
      "Epoch 110/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6788 - accuracy: 0.4958 - val_loss: 3.4699 - val_accuracy: 0.2135\n",
      "Epoch 111/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6785 - accuracy: 0.5239 - val_loss: 3.4625 - val_accuracy: 0.2360\n",
      "Epoch 112/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6706 - accuracy: 0.5070 - val_loss: 3.4164 - val_accuracy: 0.2135\n",
      "Epoch 113/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6630 - accuracy: 0.5831 - val_loss: 3.4236 - val_accuracy: 0.2472\n",
      "Epoch 114/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6600 - accuracy: 0.5634 - val_loss: 3.4425 - val_accuracy: 0.2360\n",
      "Epoch 115/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6620 - accuracy: 0.5380 - val_loss: 3.5016 - val_accuracy: 0.2360\n",
      "Epoch 116/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6625 - accuracy: 0.5549 - val_loss: 3.4196 - val_accuracy: 0.2022\n",
      "Epoch 117/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6612 - accuracy: 0.5690 - val_loss: 3.4405 - val_accuracy: 0.2360\n",
      "Epoch 118/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6615 - accuracy: 0.5831 - val_loss: 3.4663 - val_accuracy: 0.2584\n",
      "Epoch 119/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6600 - accuracy: 0.5887 - val_loss: 3.4711 - val_accuracy: 0.2584\n",
      "Epoch 120/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6583 - accuracy: 0.5746 - val_loss: 3.4652 - val_accuracy: 0.2247\n",
      "Epoch 121/121\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6567 - accuracy: 0.6028 - val_loss: 3.4689 - val_accuracy: 0.2360\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_cnn, y, epochs=121, batch_size=16, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d236d454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 673us/step\n",
      "🎵 Input Song: Drake - One Dance (Lyrics) ft. Wizkid & Kyla\n",
      "\n",
      "🎧 Recommended Songs:\n",
      "- Enno Ratrulosthayi Gani\n",
      "- Jaymes Young - Infinity [Official Audio]\n",
      "- Dua Lipa - Love Again (Official Lyrics Video)\n",
      "- Arctic Monkeys - Do I Wanna Know？ (Official Video)\n",
      "- Rude - Magic! (Audio)\n"
     ]
    }
   ],
   "source": [
    "# Predict chord profiles\n",
    "predicted_chords = model.predict(X_cnn)\n",
    "\n",
    "# Get recommendations for song at index i\n",
    "i = 110\n",
    "similarities = cosine_similarity([predicted_chords[i]], predicted_chords)[0]\n",
    "top_indices = similarities.argsort()[-6:][::-1]\n",
    "\n",
    "print(\"🎵 Input Song:\", df.iloc[i][\"Song\"])\n",
    "print(\"\\n🎧 Recommended Songs:\")\n",
    "for idx in top_indices[1:]:  # Skip self\n",
    "    print(\"-\", df.iloc[idx][\"Song\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1536c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature files\n",
    "np.save(\"X_cnn.npy\", X_cnn)  # Save the CNN input features\n",
    "np.save(\"y.npy\", y)  # Save the chord histograms\n",
    "np.save(\"predicted_chords.npy\", predicted_chords)  # Save the predicted chord profiles\n",
    "\n",
    "# Save the song names\n",
    "np.save(\"song_names.npy\", np.array(df[\"Song\"].values))\n",
    "\n",
    "# Save the original features\n",
    "np.save(\"X_scaled.npy\", X_scaled)  # Save the scaled features\n",
    "np.save(\"X_padded.npy\", X_padded)  # Save the padded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5cc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('music_recommender_model.h5')  # Save in HDF5 format\n",
    "model.save('music_recommender_model')     # Save in SavedModel format\n",
    "\n",
    "# Save the model weights separately\n",
    "model.save_weights('music_recommender_weights.h5')\n",
    "\n",
    "# Save the scaler for future use\n",
    "import joblib\n",
    "joblib.dump(scaler, 'feature_scaler.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
